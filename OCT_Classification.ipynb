{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OCT Image Classification Model\n",
        "## Classify OCT Images into: Normal, DME, Drusen, or CNV\n",
        "\n",
        "This notebook implements a deep learning model to classify OCT (Optical Coherence Tomography) retinal images into four categories:\n",
        "- **Normal**: Healthy retina\n",
        "- **DME**: Diabetic Macular Edema\n",
        "- **Drusen**: Deposits under the retina\n",
        "- **CNV**: Choroidal Neovascularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q timm albumentations scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============= CONFIGURATION =============\n",
        "# Update these paths according to your Google Drive structure\n",
        "\n",
        "# Base path - CHANGE THIS TO YOUR FOLDER PATH\n",
        "BASE_PATH = '/content/drive/MyDrive/oct_major_project/'\n",
        "\n",
        "# Dataset paths - Update these according to your folder structure\n",
        "# Option 1: If you have separate folders for each class\n",
        "DATA_PATHS = {\n",
        "    'NORMAL': os.path.join(BASE_PATH, 'NORMAL 2.v1i.coco-segmentation/train'),\n",
        "    'DME': os.path.join(BASE_PATH, 'DME 2.v1i.coco-segmentation/train'),\n",
        "    'DRUSEN': os.path.join(BASE_PATH, 'drusen 3.v1i.coco-segmentation/train'),\n",
        "    'CNV': os.path.join(BASE_PATH, 'CNV 2.v1i.coco-segmentation/train')\n",
        "}\n",
        "\n",
        "# Model save path\n",
        "MODEL_SAVE_PATH = os.path.join(BASE_PATH, 'classification_models')\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Training hyperparameters\n",
        "CONFIG = {\n",
        "    'img_size': 224,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': 50,\n",
        "    'learning_rate': 0.001,\n",
        "    'num_classes': 4,\n",
        "    'train_split': 0.8,\n",
        "    'val_split': 0.1,\n",
        "    'test_split': 0.1,\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'num_workers': 0,  # Set to 0 for Google Colab to avoid multiprocessing issues\n",
        "    'model_name': 'resnet50',  # Options: resnet50, efficientnet_b0, vgg16\n",
        "}\n",
        "\n",
        "# Class mapping\n",
        "CLASS_NAMES = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
        "CLASS_TO_IDX = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
        "IDX_TO_CLASS = {idx: name for name, idx in CLASS_TO_IDX.items()}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(f\"\\nClass Mapping: {CLASS_TO_IDX}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OCTDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for OCT Images\"\"\"\n",
        "    \n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_paths: List of paths to images\n",
        "            labels: List of labels (indices)\n",
        "            transform: Optional transform to be applied on images\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = cv2.imread(img_path)\n",
        "        \n",
        "        if image is None:\n",
        "            raise ValueError(f\"Could not load image: {img_path}\")\n",
        "        \n",
        "        # Convert BGR to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Loading and Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset_paths(data_paths):\n",
        "    \"\"\"Load all image paths and their corresponding labels\"\"\"\n",
        "    all_image_paths = []\n",
        "    all_labels = []\n",
        "    \n",
        "    print(\"Loading dataset...\")\n",
        "    for class_name, folder_path in data_paths.items():\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Warning: Folder not found: {folder_path}\")\n",
        "            continue\n",
        "        \n",
        "        # Get all image files (jpg, jpeg, png)\n",
        "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "        image_files = []\n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
        "        \n",
        "        print(f\"  {class_name}: {len(image_files)} images\")\n",
        "        \n",
        "        # Add to lists\n",
        "        all_image_paths.extend(image_files)\n",
        "        all_labels.extend([CLASS_TO_IDX[class_name]] * len(image_files))\n",
        "    \n",
        "    print(f\"\\nTotal images: {len(all_image_paths)}\")\n",
        "    return all_image_paths, all_labels\n",
        "\n",
        "# Load all data\n",
        "image_paths, labels = load_dataset_paths(DATA_PATHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: train+val vs test\n",
        "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, \n",
        "    test_size=CONFIG['test_split'], \n",
        "    random_state=42, \n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Second split: train vs val\n",
        "val_size = CONFIG['val_split'] / (CONFIG['train_split'] + CONFIG['val_split'])\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    train_val_paths, train_val_labels,\n",
        "    test_size=val_size,\n",
        "    random_state=42,\n",
        "    stratify=train_val_labels\n",
        ")\n",
        "\n",
        "print(f\"Dataset Split:\")\n",
        "print(f\"  Training samples: {len(train_paths)}\")\n",
        "print(f\"  Validation samples: {len(val_paths)}\")\n",
        "print(f\"  Test samples: {len(test_paths)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Augmentation and Transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = OCTDataset(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset = OCTDataset(val_paths, val_labels, transform=val_test_transform)\n",
        "test_dataset = OCTDataset(test_paths, test_labels, transform=val_test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=CONFIG['batch_size'], \n",
        "    shuffle=True, \n",
        "    num_workers=CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=CONFIG['batch_size'], \n",
        "    shuffle=False, \n",
        "    num_workers=CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=CONFIG['batch_size'], \n",
        "    shuffle=False, \n",
        "    num_workers=CONFIG['num_workers']\n",
        ")\n",
        "\n",
        "print(\"Data loaders created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_samples(dataset, num_samples=8):\n",
        "    \"\"\"Visualize sample images from the dataset\"\"\"\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    # Get random samples\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        # Get original image (without normalization)\n",
        "        img_path = dataset.image_paths[idx]\n",
        "        label = dataset.labels[idx]\n",
        "        \n",
        "        # Load and display image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'Class: {IDX_TO_CLASS[label]}', fontsize=12, fontweight='bold')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize training samples\n",
        "print(\"Sample Training Images:\")\n",
        "visualize_samples(train_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(model_name='resnet50', num_classes=4, pretrained=True):\n",
        "    \"\"\"Create a classification model with transfer learning\"\"\"\n",
        "    \n",
        "    if model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=pretrained)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    \n",
        "    elif model_name == 'resnet18':\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "    \n",
        "    elif model_name == 'vgg16':\n",
        "        model = models.vgg16(pretrained=pretrained)\n",
        "        num_features = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "    \n",
        "    elif model_name == 'efficientnet_b0':\n",
        "        model = models.efficientnet_b0(pretrained=pretrained)\n",
        "        num_features = model.classifier[1].in_features\n",
        "        model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(\n",
        "    model_name=CONFIG['model_name'], \n",
        "    num_classes=CONFIG['num_classes'], \n",
        "    pretrained=True\n",
        ")\n",
        "model = model.to(CONFIG['device'])\n",
        "\n",
        "print(f\"Model: {CONFIG['model_name']}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
        "\n",
        "# Learning rate scheduler (reduces learning rate when validation loss plateaus)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=5\n",
        ")\n",
        "\n",
        "print(\"Training setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Training Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader, desc='Training')\n",
        "    \n",
        "    for images, labels in progress_bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{100 * correct / total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader, desc='Validation')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in progress_bar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Statistics\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100 * correct / total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Training Loop with Model Checkpointing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training history\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': []\n",
        "}\n",
        "\n",
        "# Best model tracking\n",
        "best_val_acc = 0.0\n",
        "best_model_path = os.path.join(MODEL_SAVE_PATH, 'best_oct_classifier.pth')\n",
        "\n",
        "print(\"Starting training...\\n\")\n",
        "\n",
        "for epoch in range(CONFIG['num_epochs']):\n",
        "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model, train_loader, criterion, optimizer, CONFIG['device']\n",
        "    )\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc = validate_epoch(\n",
        "        model, val_loader, criterion, CONFIG['device']\n",
        "    )\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    \n",
        "    # Print epoch results\n",
        "    print(f\"\\nEpoch Results:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_acc': val_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'config': CONFIG,\n",
        "            'class_to_idx': CLASS_TO_IDX\n",
        "        }, best_model_path)\n",
        "        print(f\"  âœ“ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
        "    \n",
        "    # Save checkpoint every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        checkpoint_path = os.path.join(MODEL_SAVE_PATH, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'history': history\n",
        "        }, checkpoint_path)\n",
        "        print(f\"  âœ“ Checkpoint saved at epoch {epoch+1}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Training completed!\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"Best model saved at: {best_model_path}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training and validation metrics\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Plot loss\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Plot accuracy\n",
        "    axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "    axes[1].plot(history['val_acc'], label='Val Accuracy', marker='s')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy (%)')\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(MODEL_SAVE_PATH, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Load Best Model and Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load(best_model_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
        "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, device):\n",
        "    \"\"\"Evaluate model and return predictions and labels\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc='Evaluating'):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "    \n",
        "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_preds, test_labels, test_probs = evaluate_model(model, test_loader, CONFIG['device'])\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Classification Report and Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_SAVE_PATH, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Normalized confusion matrix\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
        "            cbar_kws={'label': 'Percentage'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('Normalized Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_SAVE_PATH, 'confusion_matrix_normalized.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Single Image Prediction Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_single_image(model, image_path, transform, device, class_names):\n",
        "    \"\"\"\n",
        "    Predict the class of a single OCT image\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        image_path: Path to the image\n",
        "        transform: Image transformation pipeline\n",
        "        device: Device to run inference on\n",
        "        class_names: List of class names\n",
        "    \n",
        "    Returns:\n",
        "        predicted_class: Predicted class name\n",
        "        probabilities: Dictionary of class probabilities\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not load image: {image_path}\")\n",
        "    \n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    original_image = image_rgb.copy()\n",
        "    \n",
        "    # Apply transforms\n",
        "    image_tensor = transform(image_rgb).unsqueeze(0)  # Add batch dimension\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    \n",
        "    # Predict\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        predicted_idx = torch.argmax(probabilities, dim=1).item()\n",
        "    \n",
        "    # Get class name and probabilities\n",
        "    predicted_class = class_names[predicted_idx]\n",
        "    probs_dict = {class_names[i]: probabilities[0][i].item() for i in range(len(class_names))}\n",
        "    \n",
        "    return predicted_class, probs_dict, original_image\n",
        "\n",
        "\n",
        "def visualize_prediction(image, predicted_class, probabilities):\n",
        "    \"\"\"\n",
        "    Visualize the prediction with image and probability bars\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Display image\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(f'Predicted: {predicted_class}', fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Display probabilities\n",
        "    classes = list(probabilities.keys())\n",
        "    probs = list(probabilities.values())\n",
        "    colors = ['green' if c == predicted_class else 'blue' for c in classes]\n",
        "    \n",
        "    axes[1].barh(classes, probs, color=colors, alpha=0.7)\n",
        "    axes[1].set_xlabel('Probability', fontsize=12)\n",
        "    axes[1].set_title('Class Probabilities', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlim([0, 1])\n",
        "    \n",
        "    # Add probability values on bars\n",
        "    for i, (cls, prob) in enumerate(zip(classes, probs)):\n",
        "        axes[1].text(prob + 0.02, i, f'{prob:.2%}', \n",
        "                    va='center', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print detailed results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"\\nClass Probabilities:\")\n",
        "    for cls, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"  {cls:10s}: {prob:6.2%}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "print(\"Prediction functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Predict on a random test image\n",
        "random_idx = np.random.randint(0, len(test_paths))\n",
        "test_image_path = test_paths[random_idx]\n",
        "true_label = IDX_TO_CLASS[test_labels[random_idx]]\n",
        "\n",
        "print(f\"Test Image: {os.path.basename(test_image_path)}\")\n",
        "print(f\"True Label: {true_label}\")\n",
        "print(\"\\nPredicting...\")\n",
        "\n",
        "predicted_class, probabilities, image = predict_single_image(\n",
        "    model, test_image_path, val_test_transform, CONFIG['device'], CLASS_NAMES\n",
        ")\n",
        "\n",
        "visualize_prediction(image, predicted_class, probabilities)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17. Predict on Your Own Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TO PREDICT ON YOUR OWN IMAGE:\n",
        "# 1. Upload your image to Google Colab or provide the path\n",
        "# 2. Update the image_path variable below\n",
        "# 3. Run this cell\n",
        "\n",
        "# Example:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # This will prompt you to upload a file\n",
        "# image_path = list(uploaded.keys())[0]  # Get the uploaded filename\n",
        "\n",
        "# OR provide direct path:\n",
        "# image_path = '/content/drive/MyDrive/oct_major_project/my_test_image.jpg'\n",
        "\n",
        "# Uncomment and modify the lines below:\n",
        "# predicted_class, probabilities, image = predict_single_image(\n",
        "#     model, image_path, val_test_transform, CONFIG['device'], CLASS_NAMES\n",
        "# )\n",
        "# visualize_prediction(image, predicted_class, probabilities)\n",
        "\n",
        "print(\"Ready to predict on custom images!\")\n",
        "print(\"Uncomment the code above and provide your image path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18. Visualize Test Set Predictions (Sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_test_predictions(model, test_paths, test_labels, num_samples=12):\n",
        "    \"\"\"Visualize predictions on random test samples\"\"\"\n",
        "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    # Get random samples\n",
        "    indices = np.random.choice(len(test_paths), num_samples, replace=False)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        img_path = test_paths[idx]\n",
        "        true_label = IDX_TO_CLASS[test_labels[idx]]\n",
        "        \n",
        "        # Predict\n",
        "        predicted_class, probs, image = predict_single_image(\n",
        "            model, img_path, val_test_transform, CONFIG['device'], CLASS_NAMES\n",
        "        )\n",
        "        \n",
        "        # Display\n",
        "        axes[i].imshow(image)\n",
        "        \n",
        "        # Color code: green if correct, red if wrong\n",
        "        color = 'green' if predicted_class == true_label else 'red'\n",
        "        title = f'True: {true_label}\\nPred: {predicted_class}\\n({probs[predicted_class]:.1%})'\n",
        "        axes[i].set_title(title, fontsize=10, fontweight='bold', color=color)\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(MODEL_SAVE_PATH, 'test_predictions_sample.png'), \n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Visualizing test predictions...\\n\")\n",
        "visualize_test_predictions(model, test_paths, test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 19. Save Model Summary and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model summary and results\n",
        "summary = {\n",
        "    'model_name': CONFIG['model_name'],\n",
        "    'num_classes': CONFIG['num_classes'],\n",
        "    'class_names': CLASS_NAMES,\n",
        "    'class_to_idx': CLASS_TO_IDX,\n",
        "    'img_size': CONFIG['img_size'],\n",
        "    'training_samples': len(train_paths),\n",
        "    'validation_samples': len(val_paths),\n",
        "    'test_samples': len(test_paths),\n",
        "    'num_epochs': CONFIG['num_epochs'],\n",
        "    'batch_size': CONFIG['batch_size'],\n",
        "    'learning_rate': CONFIG['learning_rate'],\n",
        "    'best_val_accuracy': float(best_val_acc),\n",
        "    'test_accuracy': float(test_accuracy * 100),\n",
        "    'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "    'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "}\n",
        "\n",
        "summary_path = os.path.join(MODEL_SAVE_PATH, 'model_summary.json')\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(summary, f, indent=4)\n",
        "\n",
        "print(\"Model Summary:\")\n",
        "print(\"=\"*60)\n",
        "for key, value in summary.items():\n",
        "    print(f\"{key:25s}: {value}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nSummary saved to: {summary_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 20. Export Model for Production (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save a lightweight version for deployment\n",
        "deployment_model_path = os.path.join(MODEL_SAVE_PATH, 'oct_classifier_deployment.pth')\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'class_to_idx': CLASS_TO_IDX,\n",
        "    'idx_to_class': IDX_TO_CLASS,\n",
        "    'model_name': CONFIG['model_name'],\n",
        "    'img_size': CONFIG['img_size'],\n",
        "    'num_classes': CONFIG['num_classes']\n",
        "}, deployment_model_path)\n",
        "\n",
        "print(f\"Deployment model saved to: {deployment_model_path}\")\n",
        "print(f\"File size: {os.path.getsize(deployment_model_path) / (1024*1024):.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 21. How to Load and Use the Saved Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example code to load and use the saved model in a new session\n",
        "\n",
        "\"\"\"\n",
        "# Load the model\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load('path/to/best_oct_classifier.pth')\n",
        "\n",
        "# Create model\n",
        "model = create_model(\n",
        "    model_name=checkpoint['config']['model_name'],\n",
        "    num_classes=checkpoint['config']['num_classes'],\n",
        "    pretrained=False\n",
        ")\n",
        "\n",
        "# Load weights\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Predict on new image\n",
        "predicted_class, probabilities, image = predict_single_image(\n",
        "    model, 'path/to/image.jpg', transform, device, CLASS_NAMES\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "print(\"See the code above for how to load and use the model in a new session.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What This Notebook Does:\n",
        "1. âœ… Loads OCT images from multiple classes (Normal, DME, Drusen, CNV)\n",
        "2. âœ… Splits data into train/val/test sets\n",
        "3. âœ… Applies data augmentation for better generalization\n",
        "4. âœ… Uses transfer learning (ResNet50, VGG16, or EfficientNet)\n",
        "5. âœ… Trains the model with automatic checkpointing\n",
        "6. âœ… Saves the best model based on validation accuracy\n",
        "7. âœ… Evaluates on test set with detailed metrics\n",
        "8. âœ… Provides single image prediction functionality\n",
        "9. âœ… Generates visualizations and reports\n",
        "\n",
        "### Key Files Generated:\n",
        "- `best_oct_classifier.pth` - Best model checkpoint\n",
        "- `oct_classifier_deployment.pth` - Lightweight deployment model\n",
        "- `model_summary.json` - Model configuration and results\n",
        "- `training_history.png` - Training curves\n",
        "- `confusion_matrix.png` - Confusion matrix visualization\n",
        "\n",
        "### Next Steps:\n",
        "1. Use the trained model for predictions\n",
        "2. Integrate into a web application\n",
        "3. Deploy for real-world use\n",
        "\n",
        "---\n",
        "**Good luck with your project! ðŸš€**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
